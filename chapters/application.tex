\chapter{Application}\label{D:application}

The main goal of this chapter is to develop the tasks related to the application, including to prepare LMS to be deployed as a cloud service and to give support for internal and external monitoring.

\section{REST API}

As mentioned previous chapters, it is required to develop an API ready to be used over cloud environments in order to ease creating specific and new applications over the LMS framework, and thus to demonstrate the viability of this thesis prototype.

Nowadays, the common and widely used format for cloud services intercommunication is JSON, as it is also used for the TCP socket API of the LMS framework. Therefore, this API middleware is going to follow such requirement.

A suitable technology to work with JSON formatted messages is Node.js \cite{nodejs} which is widely known for its good performance. Node.js is an open source, cross-platform runtime environment for server-side and networking applications. It provides an event-driven architecture and a non-blocking I/O API that optimizes application's throughput and scalability. This technology is commonly used for real-time web applications. 

Working with Node.js means avoiding serialization of the JSON messages by increasing services intercommunication performance (i.e.: less computational cost and less processing time). 

A common Noje.js framework for developing web applications and REST APIs is Express.js \cite{expressjs}. It is the de-facto standard server framework for Node.js. So, our middleware development is going to use Express.js routing system (URIs with HTTP request methods like GET, POST, PUT and DELETE).

Figure \ref{F:restAPI} illustrates the software structure proposal for developing the HTTP RESTfull API middleware, which is responsible for translating the TCP socket API of the LMS framework.

\begin{figure}[!htb]
\begin{center}
\includegraphics[width=1\textwidth]{./images/RESTAPI.png}
\caption{RESTfull API middleware architecture}
\label{F:restAPI}
\end{center}
\end{figure}

\begin{itemize}
\item HTTP REST API layer \hfill

This layer handles HTTP queries from external applications. It implements specific routes to handle specific HTTP queries. The first implementation will not implement multiple LMS management but single, as shown in Figure \ref{F:restAPI}.

\item Interface layer \hfill

This layer handles the body messages from the previous layer's HTTP queries and manipulates them in order to create an as much generic as possible API by adapting the messages to be sent through following TCP socket layer.

\item TCP socket layer \hfill

This layer is the responsible for sending and receiving JSON-formatted TCP socket messages to and from the targeted LMS instance.
\end{itemize}

As presented in Section \ref{SOA:LMS} and detailed in Appendix \ref{ANX:lmsarchfull}, there are two different management layers: the generic one and the filter specific one. So, by following this organization, the proposed API's structure is as described in Appendix \ref{ANX:RESTAPI}.

Note that this API is not implementing persistence\footnote{Persistence, in computer science, refers to the characteristic of state that outlives the process that created it. This is usually solved by storing the state's application as data structures in databases.} because the state (managed through 'State' method) is given by the LMS instance itself. The unique sign of persistence is regarding the LMS host and port which the middleware is connected to (managed through 'Connect' and 'Disconnect' methods). Higher levels of persistence should be implemented by external applications, which implies specific scenarios and requirements (i.e.: specific persistence).

For more details about how this is structured and the overall middleware is implemented check Appendix \ref{ANX:sourceCodes} with the code. 

\section{Network metrics}

Network metrics could be treated as external metrics. This is because these metrics are specially dependent from sources which transmit to LMS, the receivers from LMS and the state of the network itself. Obviously, the performance of the LMS affects to the metrics gathered too, but this effect is intended to be minimized, at least in a gathering and presentation of the metrics' point of view.

\subsection{Input network metrics}

As mentioned in Section \ref{B:appLayerCH2}, input network metrics are going to be implemented by carrying out methods re-implementations of methods provided by the Live555 library, which is the library that will manage network streams.  

\begin{figure}[!htb]
\begin{center}
\includegraphics[width=0.45\textwidth]{./images/SourceManager.png}
\caption{Input network metrics structure}
\label{F:inms}
\end{center}
\end{figure}

By following the LiveMediaStreamer architecture structure, input network implementations are going to be developed inside the 'liveMediaInput' structure. Specifically, a new class is developed, called 'SCSSubsessionStats'. This class is managed by the 'StreamCleanState' class, which is a class related to each stream 'Session' class managed by the 'SourceManager' class. This last class is a 'HeadFilter' class. Figure \ref{F:inms} shows the inter-class structure.

By initializing new RTP or RTSPClient sessions (i.e.: network inputs), a group of subessions is associated per each stream (i.e.: an RTP session has one subsession associated and the RTSPClient session has as many subsessions as accepted from the SDP that defines different RTP sessions).

When a new subsession is set, a new RTPReceiverStats class is automatically initialized. This Live555 object implements RTCP stats measurement which are only required to be treated outside. This is done at SCSSubsessionState, which creates a new schedule to periodically measure and save current state (a default granularity of 1 second is set). The implemented method is called periodically as shown in Appendix \ref{ANX:appALG} Section \ref{inmm}. This implementation prepares the metrics that are going to be presented when a new state query is received. The code in Appendix \ref{ANX:appALG} Section \ref{inmm} shows how metrics from the Live555 library are obtained. For a more detailed insight of the overall implementation see Appendix \ref{ANX:sourceCodes}. The metrics that are presented per each new state query are shown next (a default granularity of 1 second is set):

\begin{itemize}
\item Bitrate: maximum, minimum and average in kbps.
\item Packet loss percentage: maximum, minimum and average.
\item Inter-packet gap: maximum, minimum and average in milliseconds.
\item Jitter: maximum, minimum and current inter-packet gap variation in microseconds.
\end{itemize}

All these metrics are measured through previous algorithm shown which is executed each second (it is the default value set for all metrics gathered indeed). Specifically, bitrate is measured by dividing the total number bytes, received during each scheduled period, by the elapsed time given by the Live555 library implementation:

\begin{equation}\label{E:bitrate}
average\ bitrate (kbps) = \frac{kbits\ received}{elapsed\ seconds}
\end{equation}

The maximum and the minimum bitrates are the last maximum and minimum average bitrates obtained, and this is done for all other metrics.

Jitter is measured as the estimate of the statistical variance of the RTP data interarrival time inserted in the interarrival jitter field of reception reports (in microseconds), and this is already internally done by the Live555 library. So, what is presented is the current jitter value at the beginning of each new schedule.

Another metric that might be of interest is the delay from the stream source to the LMS instance but it is discarded due to not being offered from Live555 library. Moreover, it has been discared to be implemented at SCSSubsessionStats class level due to is computational cost and complexity to develop such requirement. Note that this metric is not relevant because network performance problems can be detected through other metrics already gathered (i.e.: jitter and packet loss ratio).


\subsection{Output network metrics}

As done in previous section, output network metrics are going to be implemented by carrying out re-implementations of methods given by the Live555 library.

This implementation has been much more difficult due to not having control of the creation or deletion of the RTPSink class of the Live555 library. Previous developments before the final version were based over the RTPSink re-implementation already done per each OnDemandServerMediaSubsession (Live555 library class), which is also re-implemented by QueueServerMediaSubsession (LMS framework class). But the implementation was still losing the specific RTPSink instance of specific subsession.

In order to continue with the development, an e-mail was sent to the Live555 developers mailing list and a solution was provided by Ross Finlayson as shown in Appendix \ref{ANX:emailRoss}.

The best option, as suggested by Ross, was to re-implement the RTCPInstance class per each inheriting class of the OnDemandServerMediaSubsession class, specifically the inheriting classes of the QueueServerMediaSubsession class. 

\begin{figure}[!htb]
\begin{center}
\includegraphics[width=0.45\textwidth]{./images/SinkManager.png}
\caption{Output network metrics structure}
\label{F:onms}
\end{center}
\end{figure}

Figure \ref{F:onms} shows the relationship between the SinkManager class with both possible types of connections (RTP or RTSP). Each Connetion object has a map of objects of the re-implemented RTCPInstance class, called ConnRTCPInstance (i.e.: RTCP instances per each connection). Then, each time a new specific RTP connection or any QueueServerMediaSubsession (RTSP connection, from RTSP server) is created, a ConnRTCPInstance is associated in order to start gathering the statistics offered from Live555 library. This is shown in Appendix \ref{ANX:appALG} Section \ref{onmm}, with the code of the method that is periodically called (default periodicity value is set to 1 second). In this case, the delay metric is gathered from the Live555 library.

The metrics are:

\begin{itemize}
\item Bitrate: maximum, minimum and average in kbps.
\item Packet loss percentage (ratio): maximum, minimum and current.
\item Round trip delay: maximum, minimum and current in milliseconds.
\item Jitter: maximum, minimum and current inter-packet gap variation in microseconds.
\end{itemize}

All these metrics are measured by following the same expressions used for the input network metrics.

\section{Pipeline metrics}

The following metrics are presented as the internal metrics. Please, note that the measurement of these metrics interfere the overall performance of the LMS framework. Therefore, to achieve the minimum possible computational cost is a must. But, first of all, let us pick up the example figure of a pipeline from Appendix \ref{ANX:lmsarchfull} in order to showcase the internal pipeline structure of the LMS framework. As described in Appendix \ref{ANX:lmsarchfull}, this will help understanding the following two implementations.

\begin{figure}[!htb]
\begin{center}
\includegraphics[width=1\textwidth]{./images/LMSpipelineBasicOne.png}
\caption{LMS framwork's internal pipeline structure example}
\label{F:lmsps}
\end{center}
\end{figure}

Note that in Figure \ref{F:lmsps} the arrows are the queues which interconnect each filter's writer with another filter's reader. Writers and readers are subclasses of the IOInterface class.

\subsection{Delay}

This metric is related to the time that data (i.e.: a video frame, an audio sample,\ldots) takes to be processed from an origin point to an end point by an unique given path, and this is measured from a given and required time: the data's timestamps. Data inside the LMS source code is known as a "frame", which can be an audio frame (i.e.: sample), a H264 video NAL unit, a raw frame, \ldots 

The delay time is not measured per each filter in order to not affect the overall performance, but each measured time involves an origin filter which resets the timestamps. These origins are the Head (i.e.: receiver) and OneToMany (i.e.: audio and video mixer) filters. These filters reset the frames' timestamps in order to reach and control an internal synchronization, and this is due to the fact that these filters have many outputs (i.e.: writers) or many inputs (i.e.: readers) and they require synchronizing their outputs in order to assure one point of time control inside the LMS framework, whatever the scenario configured.

So, in order to measure the delay it is important to note that a pipeline is not composed by an unique path (see Appendix \ref{ANX:lmsarchfull} for clarifications) but multiple paths. This fact implies that it is not possible to measure an unique overall delay time per frame which goes over the pipeline\footnote{There is a special case when there is only a path that defines the pipeline itself (e.g.: a path for only transcoding video with one quality: a receiver, a decoder, a re-sampler, an encoder and a transmitter, all connected within a path that defines the pipeline of this specific scenario)}, or at least it is not suitable for performance issues, but it can be done for external applications which know the scenario configuration and gathers such metrics. Therefore, this is solved by splitting the measurements by paths. And this is an optimal measurement: the delay is given by the differential time measured by the last reader of the path (i.e.: the reader of the destination filter). Appendix \ref{ANX:appALG} Section \ref{pdmm} shows the method which implements the measurement inside the Reader class.

In summary, the code measure the average delay of a frame by a given window time (default is configured to 1 second) with a resolution of microseconds. And this means measuring from the origin time, which, as said, is set by the origin filters (i.e.: the beginning of a path, starting from a writer), to each reader of the path (i.e.: each filter). But, the delay time presented is from the beginning (i.e.: initial writer of the path) until the last reader. Figure \ref{F:lmsps} illustrates different path examples.

\subsection{Losses}

This metric follows a similar criteria as the previous one. This is solved by measuring at the same point, but it is done when flushing frames at the reader side (as presented in Section \ref{B:appLayerCH2}). In order to reach minimal computational cost, the measurement is just a counter of the overall data losses when calling the flush methods. What is done is a method encapsulation by defining a parent method that is just incrementing its reader counter and then it calls the specific flush implementation per each data/frame type.

In order to properly present it to external applications it is required to be presented at a path level as done for the delay metrics. So, in this case it is only required to sum up the overall losses of the path's readers.

It is important to note that this metric is not referenced to a total data processed or at any time point, but measuring its continuity over time permits detect losses with different thresholds. This means that if this value is incrementing gradually then the system is not working properly. Such detections might imply fast increments on its continuity (differential increase). 

Note that Pipeline metrics are measured when flushing frames (discarding) or when a reader is able to remove a frame from its belonging queue. 

Finally, once previous developments are carried out a first step to offer a cloud real-time media production service is achieved. This means, offering a RESTful API and a status layer for monitoring external and internal performance of the platform.