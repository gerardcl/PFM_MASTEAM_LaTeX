\chapter{Monitoring layer}\label{G:monitoringLayer}

As already discussed, in order to properly manage a cloud computing environment it is strongly required to use monitoring tools in order to gather information of interest by improving the environment itself or by finding out issues and solving them as fast as possible.

This chapter aims to showcase how the selected monitoring tools can fit in the architecture type that has been proposed. And, how they can be used. This means, preparing the environment to support Collectd (i.e.: monitoring and gathering) and Graphite (i.e.: storing and presenting) tools.

Moreover, to point out that such tools are helpful to demonstrate that LiveMediaStreamer framework could be deployed as the core of a real-time media production platform (see chapter \ref{H:platformDeploymentAndDemonstrations}).

So, to remark that the fact of creating small and reusable containers is the main goal of this chapter and, of course, the goal of this platform architecture to prototype. And, thanks to the selected monitoring tools, which are lightweight and ease configuration flexibility, this issue might be properly solved.

Then, a proposal of the monitoring architecture in a more detailed description (regarding figure \ref{F:MLAP}) is shown in figure \ref{F:maex}.

\begin{figure}[htb]
\begin{center}
\includegraphics[width=0.9\textwidth]{./images/monitArchProp.png}
\caption{Detailed monitoring architecture}
\label{F:maex}
\end{center}
\end{figure}

Figure \ref{F:maex} showcases the relationship between different containers and the whole Collectd+Graphite deployment. Following sections are explaining it:

\section{Monitoring containers}

This section is based on how Collectd can be configured and deployed in order to monitor and properly gather metrics of interest.

\subsection{From O.S. point of view}

The fact of using Collectd means a wide community behind, which probably have already developed required functionalities (i.e.: plugins). And this is the case: in order to monitor each of the containers that a host O.S. might have it can be solved by configuring already existing plugins for Collectd from Docker community. 

The selected plugin is using the stats API introduced since Docker 1.5 version. And, concretely, the reported container's stats are:
 
\begin{itemize}
\item Network bandwidth
\item Memory usage
\item CPU usage
\item Block IO
\end{itemize}

The pluguin is called "docker-collectd-pluguin" and can be found in \href{https://github.com/lebauce/docker-collectd-plugin}{GitHub} (--REFERENCE--).

Therefore, the O.S. system requires having a basic collectd daemon running and to be configured in order to send gathered metrics to a centralized collectd server (as proposed in figure \ref{F:maex}).

So, from O.S. point of view, next example of this specific Collectd's plugins configuration showcases how to load and configure such plugins:

\begin{verbatim}

TypesDB "/usr/share/collectd/docker-collectd-plugin/dockerplugin.db"
LoadPlugin python

<Plugin python>
  ModulePath "/usr/share/collectd/docker-collectd-plugin"
  Import "dockerplugin"

  <Module dockerplugin>
    BaseURL "unix://var/run/docker.sock"
    Timeout 3
  </Module>
</Plugin>

LoadPlugin network
<Plugin network>
  Server "graphite-host-address" "graphite-host-port"
  ReportStats true
</Plugin>

\end{verbatim}

Previous Collectd configuration file sets the python (i.e.: docker-collectd-plugin) plugin as an input from the O.S. Docker API daemon and the network plugin as an output to the Collectd server.

\subsection{From container point of view}

From a container point of view and by following the premise to build containers as reusable as possible what is proposed to implement is a container that has the goal to gather the logged stats from an LMS container. This, as shown in figure \ref{F:maex}, implies sharing a Docker volume (as introduced in previous chapter \ref{D:virtualization}) from LMS container to the Collectd client which is using the tail plugin as an input. Moreover, in order to send specific logged metrics to the Collectd server container it is also using the network plugin as done in previous Collectd client configuration.

But, first of all, it is also required to be built in a container. So, this is the Docker file:

\begin{verbatim}

FROM    ubuntu:14.04
MAINTAINER Gerard CL <gerardcl@gmail.com>

ENV     DEBIAN_FRONTEND noninteractive

RUN apt-get update
RUN apt-get -y install collectd curl python-dev python-pip

ADD collectd.conf.tpl /etc/collectd/collectd.conf.tpl

RUN pip install envtpl
ADD start_container /usr/bin/start_container
RUN chmod +x /usr/bin/start_container
CMD start_container

\end{verbatim}

The, what is done in this case is to specify a bash script to run as CMD. This runs collectd but after envtpl python's package sets the environment parameters:
\begin{verbatim}
#!/bin/bash
envtpl /etc/collectd/collectd.conf.tpl
collectd -C /etc/collectd/collectd.conf -f
\end{verbatim}

Thanks to the envtpl package it is possible to run the container with specific environment variables in order to configure following parameters:

\begin{itemize}
\item LMS NAME \hfill

this will be used to identify the LMS instance in a container which Collectd is monitoring.
\item GRAPHITE HOST \hfill

this is to set the address of the remote/local container where the Collectd server is listening and pushing the metrics inside the Graphite's tools.
\item GRAPHITE PORT \hfill

this is the port where the Collect server and Graphite's tools container is listening to.
\end{itemize}

And these parameters are set in the Collectd configuration file as shown next (among the specific plugins):

\begin{verbatim}
Hostname "{{ LMS_NAME }}"
FQDNLookup true

Interval 1
Timeout 4
ReadThreads 5

LoadPlugin syslog
LoadPlugin cpu
LoadPlugin load
LoadPlugin memory
LoadPlugin network

<Plugin "syslog">
  LogLevel "info"
  NotifyLevel "OKAY"
</Plugin>

<Plugin network>
  Server "{{ GRAPHITE_HOST }}" "{{ GRAPHITE_PORT | default("25826") }}"
  ReportStats true
</Plugin>
\end{verbatim}

This Collectd configuration example file is loading specific system loggers plugins as inputs to be sent through the network plugin to the Collectd server.

But, in next chapter \ref{H:platformDeploymentAndDemonstrations} is shown an example of use of the Collectd tail plugin by using regular expressions. And this, as shown in figure \ref{F:maex}, this tail plugin is listening in an specific folder which is shared through the Docker's volume functionality with the LMS container, which logs its metrics in the same volume.

Finally, the Docker run command where the specific environment variables are set should be as shown next:
\begin{verbatim}
$ docker run -it -e "LMS_NAME=lms" \
	-e "GRAPHITE_HOST=<IP address>" -e "GRAPHITE_PORT=25826" \
	--rm --name cdc \
	-p 25826:25826/udp gerardcl/lms-collectd-client
\end{verbatim}

This will start immediately sending the defined container stats to the Graphite container specified by the environment parameters.

So, this example of deployed container for isolated Collectd clients is a key point in the general monitoring architecture.

\section{Showcasing monitoring}

container amb graphite + collectd server

mostrar com es genera tot (refer√®ncies a fitxers externs??) i imatges del graphite o escenari sencer. amb exemples concrets mostrant potencial de graphite!!!